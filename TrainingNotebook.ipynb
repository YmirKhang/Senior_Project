{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Senior Project Notebook  \n",
    "In the first phase I have downloaded the matched dataset from the Lakh Midi Dataset and cleared the songs with duplicate midi files after that I have run a web scraper for spotify api to get the features about the songs from spotify like tempo, danceability and so on. I have tried to match artists and songs that were available in spotify. After removing all the duplicates and unmatched songs 3800 songs are left for training\n",
    "Songs are in the clear_midi file,where the folder name specifies the artist name and the file name specifies the artist name. The scraper I have used stores the data in a file called statistics.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "note_dict = {\n",
    "        'C':0,\n",
    "        'D':2,\n",
    "        'E':4,\n",
    "        'F':5,\n",
    "        'G':7,\n",
    "        'A':9,\n",
    "        'B':11\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get numerical note value from text\n",
    "def get_notes(text):\n",
    "    val = (int(text[-1]) - 1) * 12\n",
    "    val = val + note_dict[text[0]]\n",
    "    if text[1] == '-':\n",
    "        val = val -1\n",
    "    elif text[1] == '#':\n",
    "        val = val + 1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data construction  \n",
    "Here we construct a matrix with rows as the duration * 4 to take each row as a quarter note  \n",
    "And the columns consists of 73 notes from C1 to C7 and additional duration feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_input(artist, song, key):\n",
    "    midi = converter.parse('./clean_midi/' + artist+'/'+ song + '.mid')\n",
    "    notes_to_parse = None\n",
    "    parts = instrument.partitionByInstrument(midi)\n",
    "    \n",
    "    if parts: \n",
    "        # get the track with the most notes from the instruments\n",
    "        notes_to_parse = max(parts.parts, key=lambda p: p.__len__()).flat.notes\n",
    "    else: \n",
    "        #single instrument\n",
    "        notes_to_parse = midi.flat.notes\n",
    "    transposed = transpose(notes_to_parse, key, notes_to_parse.analyze('ambitus').noteStart, notes_to_parse.analyze('ambitus').noteEnd)\n",
    "    print(\"Range before transpose: \",notes_to_parse.analyze('ambitus').noteEnd,notes_to_parse.analyze('ambitus').noteStart)\n",
    "    print(\"Range after  transpose: \",transposed.analyze('ambitus').noteEnd,transposed.analyze('ambitus').noteStart)\n",
    "    duration = notes_to_parse.duration.quarterLength\n",
    "    notes = np.zeros((ceil(duration*4), 74))\n",
    "    for element in transposed:\n",
    "        if isinstance(element, note.Note):\n",
    "            timestep = int(round(element.offset*4)) \n",
    "            notes[timestep, get_notes(element.pitch.nameWithOctave)] = element.volume.velocityScalar\n",
    "            notes[timestep, 73] = max(notes[timestep, 73], element.duration.quarterLength)\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            timestep = int(round(element.offset*4)) \n",
    "            for part in element:\n",
    "                notes[timestep, get_notes(part.pitch.nameWithOctave)] = part.volume.velocityScalar\n",
    "            notes[timestep, 73] = max(notes[timestep, 73], element.duration.quarterLength)     \n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(note_stream, key,spectrumStart,spectrumEnd):\n",
    "    start = get_notes(spectrumStart.nameWithOctave)\n",
    "    if (key < 6) and (key<=start):\n",
    "        offset = -1 * key \n",
    "    else:\n",
    "        offset = 12 - key\n",
    "    return note_stream.transpose(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv('./statistics.csv')\n",
    "selected_song = songs.iloc[2671]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-6 C2\n",
      "G#6 B-1\n"
     ]
    }
   ],
   "source": [
    "input = midi_to_input(selected_song.artist_name, selected_song.song_name, selected_song.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_song.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
